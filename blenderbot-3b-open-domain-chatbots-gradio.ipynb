{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <h><center>BlenderBot (3billion): Open Domain Chatbot</center></h>\n\n<img src=\"https://geekflare.com/wp-content/uploads/2016/11/chatbot-1.png\">\n\n## **About BlenderBot:**\n\n***Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.***\n\n### **Paper: [link](https://arxiv.org/pdf/1907.06616.pdf)**\n\n### **Reference: [link](https://parl.ai/projects/recipes/)**\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# **Install Gradio**","metadata":{}},{"cell_type":"code","source":"!pip install gradio","metadata":{"execution":{"iopub.status.busy":"2023-08-16T17:24:14.477531Z","iopub.execute_input":"2023-08-16T17:24:14.477898Z","iopub.status.idle":"2023-08-16T17:24:31.495921Z","shell.execute_reply.started":"2023-08-16T17:24:14.477868Z","shell.execute_reply":"2023-08-16T17:24:31.494572Z"},"_kg_hide-output":true,"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting gradio\n  Downloading gradio-3.40.1-py3-none-any.whl (20.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (22.1.0)\nRequirement already satisfied: aiohttp~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.8.4)\nRequirement already satisfied: altair<6.0,>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (5.0.1)\nRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio) (0.98.0)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting gradio-client>=0.4.0 (from gradio)\n  Downloading gradio_client-0.4.0-py3-none-any.whl (297 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.4/297.4 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting httpx (from gradio)\n  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: huggingface-hub>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.16.4)\nRequirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.10/site-packages (from gradio) (5.12.0)\nRequirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.1.2)\nRequirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.2.0)\nRequirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.3)\nRequirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.7.1)\nCollecting mdit-py-plugins<=0.3.3 (from gradio)\n  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy~=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.23.5)\nRequirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.9.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from gradio) (21.3)\nRequirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.5.3)\nRequirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (9.5.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.10.9)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\nCollecting python-multipart (from gradio)\n  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.0)\nRequirement already satisfied: requests~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.31.0)\nCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.6.3)\nRequirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.22.0)\nRequirement already satisfied: websockets<12.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (11.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp~=3.0->gradio) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp~=3.0->gradio) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp~=3.0->gradio) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp~=3.0->gradio) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp~=3.0->gradio) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp~=3.0->gradio) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp~=3.0->gradio) (1.3.1)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (4.17.3)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client>=0.4.0->gradio) (2023.6.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.14.0->gradio) (3.12.2)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.14.0->gradio) (4.65.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\nRequirement already satisfied: linkify-it-py<3,>=1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.40.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.4)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests~=2.0->gradio) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests~=2.0->gradio) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests~=2.0->gradio) (2023.5.7)\nRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (8.1.3)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\nRequirement already satisfied: starlette<0.28.0,>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio) (0.27.0)\nCollecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio)\n  Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->gradio) (1.3.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.7.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.19.3)\nRequirement already satisfied: uc-micro-py in /opt/conda/lib/python3.10/site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx->gradio) (1.1.1)\nBuilding wheels for collected packages: ffmpy\n  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5596 sha256=8a3f57e8bd29afbc7b510264a9301efe8dc23f2b1ed03c65675f59b2a9a5a6ed\n  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\nSuccessfully built ffmpy\nInstalling collected packages: ffmpy, semantic-version, python-multipart, mdit-py-plugins, httpcore, httpx, gradio-client, gradio\n  Attempting uninstall: mdit-py-plugins\n    Found existing installation: mdit-py-plugins 0.4.0\n    Uninstalling mdit-py-plugins-0.4.0:\n      Successfully uninstalled mdit-py-plugins-0.4.0\nSuccessfully installed ffmpy-0.3.1 gradio-3.40.1 gradio-client-0.4.0 httpcore-0.17.3 httpx-0.24.1 mdit-py-plugins-0.3.3 python-multipart-0.0.6 semantic-version-2.10.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Import Necessary Library**","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nimport gradio as gr","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-16T17:29:08.915489Z","iopub.execute_input":"2023-08-16T17:29:08.916440Z","iopub.status.idle":"2023-08-16T17:29:08.921201Z","shell.execute_reply.started":"2023-08-16T17:29:08.916403Z","shell.execute_reply":"2023-08-16T17:29:08.920225Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# **Load the BlenderBot Model**","metadata":{}},{"cell_type":"code","source":"# Load model\nmodel_name = \"facebook/blenderbot-400M-distill\"\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T17:24:56.537085Z","iopub.execute_input":"2023-08-16T17:24:56.537481Z","iopub.status.idle":"2023-08-16T17:25:22.580447Z","shell.execute_reply.started":"2023-08-16T17:24:56.537451Z","shell.execute_reply":"2023-08-16T17:25:22.579189Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.57k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45cfd9a955e3454bbc8a2eaa05706d25"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/730M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3d3c091641e4ecf9eb452525bbd6703"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f1d0db3a59b4c1eaa1f510bc2435f98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83ef024a80ff445f9a841433c55e5b26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/127k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65ea0cc98db940af98c9a44ce43da8c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/62.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ecf977fbdfd4d5da54fbbc22bc13cbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)in/added_tokens.json:   0%|          | 0.00/16.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edde4c546a6d4b6ebc96a86f272fe9d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81751eee219c4ca0820e7f0be5d8f080"}},"metadata":{}}]},{"cell_type":"markdown","source":"# **Conversional Bot Function**","metadata":{}},{"cell_type":"code","source":"conversation_history = []\n\ndef chat(input_text):\n    conversation_history.append(input_text)\n    history_string = \"\\n\".join(conversation_history)\n\n    inputs = tokenizer.encode_plus(history_string, return_tensors=\"pt\")\n    outputs = model.generate(**inputs)\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n\n    conversation_history.append(response)\n    return response\n","metadata":{"execution":{"iopub.status.busy":"2023-08-16T17:27:22.368288Z","iopub.execute_input":"2023-08-16T17:27:22.368685Z","iopub.status.idle":"2023-08-16T17:27:22.375217Z","shell.execute_reply.started":"2023-08-16T17:27:22.368657Z","shell.execute_reply":"2023-08-16T17:27:22.373955Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# **Gradio Deployment**","metadata":{}},{"cell_type":"code","source":"demo = gr.Interface(\n    fn=chat,\n    inputs=gr.inputs.Textbox(placeholder=\"Start a conversation...\"),\n    outputs=gr.outputs.Textbox(),\n    live=False,\n    title=\"VK Open Domain Conversional chatbot\",\n    description=\"Have a conversation with the chatbot.\",\n    allow_screenshot=True,\n    allow_flagging=\"never\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T17:31:03.628281Z","iopub.execute_input":"2023-08-16T17:31:03.628676Z","iopub.status.idle":"2023-08-16T17:31:03.670216Z","shell.execute_reply.started":"2023-08-16T17:31:03.628648Z","shell.execute_reply":"2023-08-16T17:31:03.669140Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_32/1089023682.py:3: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n  inputs=gr.inputs.Textbox(placeholder=\"Start a conversation...\"),\n/tmp/ipykernel_32/1089023682.py:3: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n  inputs=gr.inputs.Textbox(placeholder=\"Start a conversation...\"),\n/tmp/ipykernel_32/1089023682.py:3: GradioDeprecationWarning: `numeric` parameter is deprecated, and it has no effect\n  inputs=gr.inputs.Textbox(placeholder=\"Start a conversation...\"),\n/tmp/ipykernel_32/1089023682.py:4: GradioDeprecationWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n  outputs=gr.outputs.Textbox(),\n/tmp/ipykernel_32/1089023682.py:1: GradioDeprecationWarning: `allow_screenshot` parameter is deprecated, and it has no effect\n  demo = gr.Interface(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Result**","metadata":{}},{"cell_type":"code","source":"demo.launch(share=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T17:31:08.337646Z","iopub.execute_input":"2023-08-16T17:31:08.338016Z","iopub.status.idle":"2023-08-16T17:31:12.910834Z","shell.execute_reply.started":"2023-08-16T17:31:08.337986Z","shell.execute_reply":"2023-08-16T17:31:12.909967Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Running on local URL:  http://127.0.0.1:7861\nRunning on public URL: https://76a173cfdc728d3315.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://76a173cfdc728d3315.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1353: UserWarning: Using `max_length`'s default (60) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Close Gradio link**","metadata":{}},{"cell_type":"code","source":"#gr.close_all()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **🤗Thank you! Happy Learning🤗**","metadata":{}}]}